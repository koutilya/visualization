{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from difflib import SequenceMatcher\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sys.path.append('/sanskrit_transcoder')\n",
    "# import transcoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\",\"sanskrit_transcoder/transcoder.py\")\n",
    "transcoder = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(transcoder)\n",
    "transcoder.transcoder_set_dir('sanskrit_transcoder/data/transcoder');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>I</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>u</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>U</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>q</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>q</td>\n",
       "      <td>a q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>Q</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>L</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>L</td>\n",
       "      <td>a L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>a</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>a</td>\n",
       "      <td>o</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>a</td>\n",
       "      <td>k</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>a</td>\n",
       "      <td>K</td>\n",
       "      <td>aK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>ag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>a</td>\n",
       "      <td>G</td>\n",
       "      <td>aG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>acC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>aj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>a</td>\n",
       "      <td>J</td>\n",
       "      <td>aJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>F</td>\n",
       "      <td>aF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>a</td>\n",
       "      <td>T</td>\n",
       "      <td>aT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>a</td>\n",
       "      <td>D</td>\n",
       "      <td>aD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>aN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2535</td>\n",
       "      <td>eH</td>\n",
       "      <td>s</td>\n",
       "      <td>eH s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2536</td>\n",
       "      <td>oH</td>\n",
       "      <td>r</td>\n",
       "      <td>orr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2537</td>\n",
       "      <td>oH</td>\n",
       "      <td>S</td>\n",
       "      <td>oSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2538</td>\n",
       "      <td>oH</td>\n",
       "      <td>S</td>\n",
       "      <td>oH S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>2539</td>\n",
       "      <td>oH</td>\n",
       "      <td>R</td>\n",
       "      <td>oRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>2540</td>\n",
       "      <td>oH</td>\n",
       "      <td>R</td>\n",
       "      <td>oH R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>2541</td>\n",
       "      <td>oH</td>\n",
       "      <td>s</td>\n",
       "      <td>oss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>2542</td>\n",
       "      <td>oH</td>\n",
       "      <td>s</td>\n",
       "      <td>oH s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2543</td>\n",
       "      <td>EH</td>\n",
       "      <td>r</td>\n",
       "      <td>Err</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>2544</td>\n",
       "      <td>EH</td>\n",
       "      <td>S</td>\n",
       "      <td>ESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>2545</td>\n",
       "      <td>EH</td>\n",
       "      <td>S</td>\n",
       "      <td>EH S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2546</td>\n",
       "      <td>EH</td>\n",
       "      <td>R</td>\n",
       "      <td>ERR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>2547</td>\n",
       "      <td>EH</td>\n",
       "      <td>R</td>\n",
       "      <td>EH R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>2548</td>\n",
       "      <td>EH</td>\n",
       "      <td>s</td>\n",
       "      <td>Ess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>2549</td>\n",
       "      <td>EH</td>\n",
       "      <td>s</td>\n",
       "      <td>EH s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>OH</td>\n",
       "      <td>r</td>\n",
       "      <td>Orr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2551</td>\n",
       "      <td>OH</td>\n",
       "      <td>S</td>\n",
       "      <td>OSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>2552</td>\n",
       "      <td>OH</td>\n",
       "      <td>S</td>\n",
       "      <td>OH S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>2553</td>\n",
       "      <td>OH</td>\n",
       "      <td>R</td>\n",
       "      <td>ORR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2554</td>\n",
       "      <td>OH</td>\n",
       "      <td>R</td>\n",
       "      <td>OH R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2555</td>\n",
       "      <td>OH</td>\n",
       "      <td>s</td>\n",
       "      <td>Oss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2556</td>\n",
       "      <td>OH</td>\n",
       "      <td>s</td>\n",
       "      <td>OH s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2557</td>\n",
       "      <td>H</td>\n",
       "      <td>k</td>\n",
       "      <td>&gt;&lt;k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2558</td>\n",
       "      <td>H</td>\n",
       "      <td>k</td>\n",
       "      <td>H k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2559</td>\n",
       "      <td>H</td>\n",
       "      <td>K</td>\n",
       "      <td>&gt;&lt;K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2560</td>\n",
       "      <td>H</td>\n",
       "      <td>K</td>\n",
       "      <td>H K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>2561</td>\n",
       "      <td>H</td>\n",
       "      <td>p</td>\n",
       "      <td>&gt;&lt;p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>2562</td>\n",
       "      <td>H</td>\n",
       "      <td>p</td>\n",
       "      <td>H p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2563</td>\n",
       "      <td>H</td>\n",
       "      <td>P</td>\n",
       "      <td>&gt;&lt;P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>2564</td>\n",
       "      <td>H</td>\n",
       "      <td>P</td>\n",
       "      <td>H P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2565 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  c1 c2    c3\n",
       "0        0   a  a     A\n",
       "1        1   a  A     A\n",
       "2        2   a  i     e\n",
       "3        3   a  I     e\n",
       "4        4   a  u     o\n",
       "5        5   a  U     o\n",
       "6        6   a  q    ar\n",
       "7        7   a  q   a q\n",
       "8        8   a  Q    ar\n",
       "9        9   a  L    al\n",
       "10      10   a  L   a L\n",
       "11      11   a  e     E\n",
       "12      12   a  E     E\n",
       "13      13   a  o     O\n",
       "14      14   a  O     O\n",
       "15      15   a  k    ak\n",
       "16      16   a  K    aK\n",
       "17      17   a  g    ag\n",
       "18      18   a  G    aG\n",
       "19      19   a  f    af\n",
       "20      20   a  c    ac\n",
       "21      21   a  C   acC\n",
       "22      22   a  j    aj\n",
       "23      23   a  J    aJ\n",
       "24      24   a  F    aF\n",
       "25      25   a  t    at\n",
       "26      26   a  T    aT\n",
       "27      27   a  d    ad\n",
       "28      28   a  D    aD\n",
       "29      29   a  N    aN\n",
       "...    ...  .. ..   ...\n",
       "2535  2535  eH  s  eH s\n",
       "2536  2536  oH  r   orr\n",
       "2537  2537  oH  S   oSS\n",
       "2538  2538  oH  S  oH S\n",
       "2539  2539  oH  R   oRR\n",
       "2540  2540  oH  R  oH R\n",
       "2541  2541  oH  s   oss\n",
       "2542  2542  oH  s  oH s\n",
       "2543  2543  EH  r   Err\n",
       "2544  2544  EH  S   ESS\n",
       "2545  2545  EH  S  EH S\n",
       "2546  2546  EH  R   ERR\n",
       "2547  2547  EH  R  EH R\n",
       "2548  2548  EH  s   Ess\n",
       "2549  2549  EH  s  EH s\n",
       "2550  2550  OH  r   Orr\n",
       "2551  2551  OH  S   OSS\n",
       "2552  2552  OH  S  OH S\n",
       "2553  2553  OH  R   ORR\n",
       "2554  2554  OH  R  OH R\n",
       "2555  2555  OH  s   Oss\n",
       "2556  2556  OH  s  OH s\n",
       "2557  2557   H  k   ><k\n",
       "2558  2558   H  k   H k\n",
       "2559  2559   H  K   ><K\n",
       "2560  2560   H  K   H K\n",
       "2561  2561   H  p   ><p\n",
       "2562  2562   H  p   H p\n",
       "2563  2563   H  P   ><P\n",
       "2564  2564   H  P   H P\n",
       "\n",
       "[2565 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.read_csv(\"all_sandhi.txt\",encoding = 'utf-8' ,sep = ',')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sandhi implemented here .\n",
    "names = [\"workdata/lines_submit/correct_lines/sorteddata/\",\"workdata/lines_submit/wrong_lines/sorteddata/\"]\n",
    "\n",
    "# fnames = os.listdir(\"workdata/lines_submit/correct_lines/sorteddata/\")\n",
    "for name in names :\n",
    "    fnames = os.listdir(name)\n",
    "    for fname in fnames:\n",
    "        if fname == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "#         print(fname+\"/dataframe.txt\")\n",
    "        with open(name+fname+\"/input_line.txt\",encoding = 'utf-8' ,mode ='r') as fr :\n",
    "            lines = fr.readlines()\n",
    "        for line in lines :\n",
    "            if(line.startswith(\"converted line : \")) :\n",
    "                line1 = line[17:]\n",
    "                break\n",
    "        chunkwords = line1.split(\"\\xa0\")\n",
    "#         print(chunkwords)\n",
    "        df = pd.read_csv(name+fname+\"/dataframe.txt\",encoding = 'utf-8' ,sep = ',')\n",
    "        cf = pd.read_csv(name+fname+\"/conflicts.csv\",encoding = 'utf-8' ,sep = ',')\n",
    "        df['word_slp1'] = df['word']\n",
    "        for i in df.index:\n",
    "            df.loc[i,'word_slp1']   =  transcoder.transcoder_processString(df.loc[i,'word'],'roman','slp1')  ##transcoder\n",
    "        df['sandhi_indexs'] = \"\"\n",
    "        df['sandhi_words'] = \"\"\n",
    "        for i in df.index : \n",
    "            word1 = df.loc[i,'word_slp1']\n",
    "            chunkno = df.loc[i,'chunk_no']\n",
    "            position1 =  df.loc[i,'position']\n",
    "            level = df.loc[i,'level']\n",
    "            color1 = df.loc[i,'color_class']\n",
    "            clspan1 = df.loc[i,'colspan']\n",
    "            chunkword = transcoder.transcoder_processString(chunkwords[chunkno-1],'roman','slp1')   ## transcoder\n",
    "            df1 = df.loc[(df['chunk_no'] == chunkno) & (df['level']!=level)]\n",
    "            for j in df1.index :\n",
    "                if (cf.loc[i,str(j)] != 1) and (cf.loc[i,str(j)] != 0):\n",
    "                    cf.loc[i,str(j)] = 2\n",
    "                position2 = df1.loc[j,'position']\n",
    "                color2 = df.loc[i,'color_class']\n",
    "                word2 = df1.loc[j,'word_slp1']\n",
    "                word3 = df1.loc[j,'word']\n",
    "                if(position2 == position1 + clspan1-1) and (clspan1!=1):\n",
    "                    if((color1=='yellow_back') and (color2=='carmin_back'))  :    ## check color\n",
    "                        continue\n",
    "                    if((color2=='yellow_back') and (color1=='carmin_back'))  :    ## check color\n",
    "                        continue\n",
    "                    if(len(s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])])):\n",
    "                        \n",
    "                        x=s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])]\n",
    "                        for c3 in x['c3']:\n",
    "                            mergeword = word1[:-1] + c3 + word2[1:]\n",
    "#                             print(mergeword+\"---\"+chunkword)\n",
    "                            if(re.findall(mergeword,chunkword)):               ## checking  mergedword(spl1) in chunkword\n",
    "                                df.loc[i,'sandhi_indexs'] += str(j)+\", \"\n",
    "                                df.loc[i,'sandhi_words'] += word3+\"(\"+word2+\"), \"\n",
    "                                cf.loc[i,str(j)] = 1                             ## merge pssible so change conflict\n",
    "                                cf.loc[j,str(i)] = 1   \n",
    "#                                 print(cf.loc[i,str(j)])\n",
    "                                break\n",
    "                    elif(word1[-1:]=='H'):\n",
    "                        if(len(s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])])):\n",
    "                        \n",
    "                            x=s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])]\n",
    "                            for c3 in x['c3']:\n",
    "                                mergeword = word1[:-1] + c3 + word2[1:]\n",
    "                                if(re.findall(mergeword,chunkword)):          ## checking  mergedword(spl1) in chunkword   \n",
    "                                    df.loc[i,'sandhi_indexs'] += str(j)+\", \"\n",
    "                                    df.loc[i,'sandhi_words'] += word3+\"(\"+word2+\"), \"\n",
    "                                    cf.loc[i,str(j)] = 1                        ## merge pssible so change conflict\n",
    "                                    cf.loc[j,str(i)] = 1 \n",
    "                                    break\n",
    "                elif(position2 > position1 + clspan1-1) :\n",
    "                    cf.loc[i,str(j)] = 0\n",
    "                    cf.loc[j,str(i)] = 0\n",
    "        \n",
    "        df.to_csv(name+fname+\"/dataframe_withsandhi.txt\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )\n",
    "        \n",
    "       ## for conflict finding 0 = no conflict,1=possible merge,2=conflict \n",
    "        for i in df.index :\n",
    "            chunkno = df.loc[i,'chunk_no']\n",
    "            position1 =  df.loc[i,'position']\n",
    "            level = df.loc[i,'level']\n",
    "            color1 = df.loc[i,'color_class']\n",
    "            clspan1 = df.loc[i,'colspan']\n",
    "            df1 = df.loc[(df['chunk_no'] != chunkno)]\n",
    "            for j in df1.index :\n",
    "                cf.loc[i,str(j)] = 0\n",
    "            df1 = df.loc[(df['level']==level) & (df['chunk_no'] == chunkno)]\n",
    "            for j in df1.index :\n",
    "                cf.loc[i,str(j)] = 0\n",
    "\n",
    "        cf.to_csv(name+fname+\"/conflicts.csv\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )               \n",
    "                        \n",
    "#         break\n",
    "#     break\n",
    "# print(name+fname+\"/dataframe_withsandhi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting undefined words,without conflict sentences for partial,complete analasys\n",
    "\n",
    "names = [\"workdata/lines_submit/correct_lines/sorteddata/\",\"workdata/lines_submit/wrong_lines/sorteddata/\"]\n",
    "\n",
    "os.makedirs('workdata/lines_submit/analasys/', exist_ok=True)\n",
    "\n",
    "pbwords = []\n",
    "\n",
    "clinefolder = []\n",
    "wlinefolder = []\n",
    "                  \n",
    "for name in names : \n",
    "    fnames = os.listdir(name)\n",
    "    for fname in fnames:\n",
    "        if fname == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if(name == names[1]):\n",
    "            \n",
    "            with open(name+fname+\"/problem_words.txt\",encoding = 'utf-8' ,mode ='r') as fr :\n",
    "                c =1\n",
    "                for line in fr.readlines() :\n",
    "                    if c==1 :\n",
    "                        c=0\n",
    "                        continue\n",
    "#                     if not line[:-1] in pbwords :\n",
    "                    pbwords.append(line[:-1])\n",
    "        \n",
    "        cf = pd.read_csv(name+fname+\"/conflicts.csv\",encoding = 'utf-8' ,sep = ',')\n",
    "        bl = 0\n",
    "        for i in range(0,len(cf)):\n",
    "            for j in range(0,len(cf)):\n",
    "                if not cf.loc[i,str(j)]==0:\n",
    "                    bl=1\n",
    "        if(bl == 0):\n",
    "            if(name==names[0]):\n",
    "                clinefolder.append(name+fname)\n",
    "            else :\n",
    "                wlinefolder.append(name+fname)\n",
    "    if(name==names[0]):\n",
    "        with open(\"workdata/lines_submit/analasys/correctlines_noconflics_folders.txt\",encoding = 'utf-8' ,mode ='w') as fw :\n",
    "            fw.writelines(\"\\n\".join(clinefolder))\n",
    "    else :\n",
    "        with open(\"workdata/lines_submit/analasys/wronglines_noconflics_folders.txt\",encoding = 'utf-8' ,mode ='w') as fw :\n",
    "            fw.writelines(\"\\n\".join(wlinefolder))\n",
    "os.makedirs('workdata/lines_submit/analasys/', exist_ok=True)\n",
    "with open(\"workdata/lines_submit/analasys/undifined_words.txt\",encoding = 'utf-8' ,mode ='w') as fw :\n",
    "    fw.writelines(\"\\n\".join(pbwords))\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"workdata/lines_submit/analasys/undifined_words.txt\",encoding = 'utf-8' ,mode ='r') as fr :\n",
    "    pbwords = fr.readlines()\n",
    "pf = pd.DataFrame(index=range(0,1))\n",
    "for pbw in pbwords:\n",
    "    pf[pbw[:-1]] = 0\n",
    "for pbw in pbwords:\n",
    "    pf[pbw[:-1]] += 1\n",
    "pf.to_csv(\"workdata/lines_submit/analasys/undifined_wordsfreaquency.csv\",encoding = 'utf-8' , sep=',',index = False,mode = 'w' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pbwords\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in names :\n",
    "    fnames = os.listdir(name)\n",
    "    for fname in fnames:\n",
    "        if fname == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        df1 = pd.read_csv(name+fname+\"/dataframe.txt\",encoding = 'utf-8' ,sep = ',')\n",
    "        df2 = df1 = pd.read_csv(name+fname+\"/dataframe_withsandhi.txt\",encoding = 'utf-8' ,sep = ',')\n",
    "        df1.to_csv(name+fname+\"/dataframe.csv\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )\n",
    "        df2.to_csv(name+fname+\"/dataframe_withsandhi.csv\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## sandhi implemented here for modifies wronglines .\n",
    "# names = [\"workdata/lines_submit/modified_wrong_lines/correct_lines/sorteddata/\",\"workdata/lines_submit/modified_wrong_lines/wrong_lines/sorteddata/\"]\n",
    "\n",
    "# # fnames = os.listdir(\"workdata/lines_submit/correct_lines/sorteddata/\")\n",
    "# for name in names :\n",
    "#     fnames = os.listdir(name)\n",
    "#     for fname in fnames:\n",
    "#         if fname == \".ipynb_checkpoints\":\n",
    "#             continue\n",
    "# #         print(fname+\"/dataframe.txt\")\n",
    "#         with open(name+fname+\"/input_line.txt\",encoding = 'utf-8' ,mode ='r') as fr :\n",
    "#             lines = fr.readlines()\n",
    "#         for line in lines :\n",
    "#             if(line.startswith(\"converted line : \")) :\n",
    "#                 line1 = line[17:]\n",
    "#                 break\n",
    "#         chunkwords = line1.split(\"\\xa0\")\n",
    "# #         print(chunkwords)\n",
    "#         df = pd.read_csv(name+fname+\"/dataframe.txt\",encoding = 'utf-8' ,sep = ',')\n",
    "#         cf = pd.read_csv(name+fname+\"/conflicts.csv\",encoding = 'utf-8' ,sep = ',')\n",
    "#         df['word_slp1'] = df['word']\n",
    "#         for i in df.index:\n",
    "#             df.loc[i,'word_slp1']   =  transcoder.transcoder_processString(df.loc[i,'word'],'roman','slp1')  ##transcoder\n",
    "#         df['sandhi_indexs'] = \"\"\n",
    "#         df['sandhi_words'] = \"\"\n",
    "#         for i in df.index : \n",
    "#             word1 = df.loc[i,'word_slp1']\n",
    "#             chunkno = df.loc[i,'chunk_no']\n",
    "#             position1 =  df.loc[i,'position']\n",
    "#             level = df.loc[i,'level']\n",
    "#             color1 = df.loc[i,'color_class']\n",
    "#             clspan1 = df.loc[i,'colspan']\n",
    "#             chunkword = transcoder.transcoder_processString(chunkwords[chunkno-1],'roman','slp1')   ## transcoder\n",
    "#             df1 = df.loc[(df['chunk_no'] == chunkno) & (df['level']!=level)]\n",
    "#             for j in df1.index :\n",
    "#                 if (cf.loc[i,str(j)] != 1) and (cf.loc[i,str(j)] != 0):\n",
    "#                     cf.loc[i,str(j)] = 2\n",
    "#                 position2 = df1.loc[j,'position']\n",
    "#                 color2 = df.loc[i,'color_class']\n",
    "#                 word2 = df1.loc[j,'word_slp1']\n",
    "#                 word3 = df1.loc[j,'word']\n",
    "#                 if(position2 == position1 + clspan1-1) and (clspan1!=1):\n",
    "#                     if((color1=='yellow_back') and (color2=='carmin_back'))  :    ## check color\n",
    "#                         continue\n",
    "#                     if((color2=='yellow_back') and (color1=='carmin_back'))  :    ## check color\n",
    "#                         continue\n",
    "#                     if(len(s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])])):\n",
    "                        \n",
    "#                         x=s.loc[(s['c1']==word1[-1:] )& (s['c2']==word2[:1])]\n",
    "#                         for c3 in x['c3']:\n",
    "#                             mergeword = word1[:-1] + c3 + word2[1:]\n",
    "# #                             print(mergeword+\"---\"+chunkword)\n",
    "#                             if(re.findall(mergeword,chunkword)):               ## checking  mergedword(spl1) in chunkword\n",
    "#                                 df.loc[i,'sandhi_indexs'] += str(j)+\", \"\n",
    "#                                 df.loc[i,'sandhi_words'] += word3+\"(\"+word2+\"), \"\n",
    "#                                 cf.loc[i,str(j)] = 1                             ## merge pssible so change conflict\n",
    "#                                 cf.loc[j,str(i)] = 1   \n",
    "# #                                 print(cf.loc[i,str(j)])\n",
    "#                                 break\n",
    "#                     elif(word1[-1:]=='H'):\n",
    "#                         if(len(s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])])):\n",
    "                        \n",
    "#                             x=s.loc[(s['c1']==word1[-2:] )& (s['c2']==word2[:1])]\n",
    "#                             for c3 in x['c3']:\n",
    "#                                 mergeword = word1[:-1] + c3 + word2[1:]\n",
    "#                                 if(re.findall(mergeword,chunkword)):          ## checking  mergedword(spl1) in chunkword   \n",
    "#                                     df.loc[i,'sandhi_indexs'] += str(j)+\", \"\n",
    "#                                     df.loc[i,'sandhi_words'] += word3+\"(\"+word2+\"), \"\n",
    "#                                     cf.loc[i,str(j)] = 1                        ## merge pssible so change conflict\n",
    "#                                     cf.loc[j,str(i)] = 1 \n",
    "#                                     break\n",
    "#                 elif(position2 > position1 + clspan1-1) :\n",
    "#                     cf.loc[i,str(j)] = 0\n",
    "#                     cf.loc[j,str(i)] = 0\n",
    "        \n",
    "#         df.to_csv(name+fname+\"/dataframe_withsandhi.txt\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )\n",
    "        \n",
    "#        ## for conflict finding 0 = no conflict,1=possible merge,2=conflict \n",
    "#         for i in df.index :\n",
    "#             chunkno = df.loc[i,'chunk_no']\n",
    "#             position1 =  df.loc[i,'position']\n",
    "#             level = df.loc[i,'level']\n",
    "#             color1 = df.loc[i,'color_class']\n",
    "#             clspan1 = df.loc[i,'colspan']\n",
    "#             df1 = df.loc[(df['chunk_no'] != chunkno)]\n",
    "#             for j in df1.index :\n",
    "#                 cf.loc[i,str(j)] = 0\n",
    "#             df1 = df.loc[(df['level']==level) & (df['chunk_no'] == chunkno)]\n",
    "#             for j in df1.index :\n",
    "#                 cf.loc[i,str(j)] = 0\n",
    "\n",
    "#         cf.to_csv(name+fname+\"/conflicts.csv\" ,encoding = 'utf-8' , sep=',',index = False,mode = 'w' )               \n",
    "                        \n",
    "# #         break\n",
    "# #     break\n",
    "# # print(name+fname+\"/dataframe_withsandhi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
